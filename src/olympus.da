Olympus:
    # Assumptions: generate_keys() is a function that initializes and returns a public-private key pair
    # Standard implementations can be found in Crypto libraries for most languages

    # Assumptions: wait_aggregate(N, func) is a function that waits till a nested function func is called n times
    # It aggregates all func operands as lists and returns them as tuples

    # Assumption: wait_for_message is a function that blockingly waits for a message and copies arguments into result

    # Assumption: hash utility function that calculates hash of the given data

    # Olympus state variables
    T                        # maximum number of failures that can be tolerated by system
    num_replicas = 2T + 1    # total replicas must be 2T + 1 to maintain consistency guarantees
    replicas = []            # replica objects
    replica_public_keys = [] # public keys of replicas
    replica_private_keys = [] # private keys of replicas
    replica_timeout

    # Olympus constructor
    Olympus (T_value, replica_timeout):
        T = T_value
        num_replicas = 2T + 1
        replica_timeout = replica_timeout


    # Olympus methods


    init():
        init_replicas([], [])  # since this is the first initialization of config, there is no history or state for replicas
        return replicas        # returns the replicas state variable


    init_replicas(running_state, history):
        for i from 1 to num_replicas:
            <replica_public_keys[i], replica_private_keys[i]> = generate_keys()
            replica[i] = generate_replica(i, running_state, history, replicas, replica_public_keys, replica_private_keys[i], replica_timeout)


    generate_replica(i, running_state, history, replicas, replica_public_keys, single_private_key):
        r = Replica(replicas, replica_public_keys, single_private_key, replica_timeout)
        replicas[i] = r
        r.state = ACTIVE
        send('init_hist', running_state, history) to r

    # This is the message received by Olympus from clients asking for configuration
    on_message_received('get_configuration', requester):
        send('configuration', replicas, replica_public_keys) to requester


    on_message_received('request_reconfiguration_client', result, result_proofs, o):
        # when Olympus receives an external reconfiguration request, i.e. from the client, it needs to verify
        # the proofs sent for reconfiguration. Hence, we do a signature verification for (T+1) result_proofs again
        verified_count = 0
        for i from 1 to num_replicas:
            if verify_signature(<o, hash(result)>, result_proofs[i], replica_public_keys[i]) == true:
                verified_count += 1

        if verified_count >= T + 1:
            # Reconfiguration request is invalid
            log ('Neglecting reconfiguration request', o)
            return
        begin_reconfiguration()


    begin_reconfiguration():
        for i = 1 to num_replicas in parallel:
            send('wedge_request') to replica[i]

        <histories, checkpoint_proofs, hashed_running_states> =
        wait_aggregate(num_replicas, on_message_received('wedge', history, checkpoint_proof, hash_running_state))
        # now we make at most T quorum attempts, each with a size of T + 1, and attempt to find a valid history
        for i from 1 to T:
            quorum_range = range (i to i + T + 1)
            quorum_result_pair = is_valid_quorum(histories (i, i + T + 1), quorum_range)
            if quorum_result_pair.first == true:
                # now, we need to get a valid running state from our quorum, and match it against the hash we got while checking validity
                for i in quorum_range:
                    send('get_running_state') to replica[i]
                    rs = wait_for_message('running_state', rs)
                    if (hash(rs) == quorum_result_pair.second):   # this means that the running state hash computed earlier while validating quorum,
                                                                  # matches the one sent by the currently queried replica. This means we can now reconfigure.
                        init_replicas(rs, lh)
                        return
        return


    # function that returns a tuple of boolean validity of quorum and hash of result
    is_valid_quorum(histories, indices):
        for each <i,j> in indices:                      # proceed for each pair <i,j> in indices, nested loop
            for <si, oi> in histories[i]:               # for each tuple <si,oi> in history[i]
                <sj, oj> = histories[j].find(<si, *>)  # find a tuple <sj, oj> in history[j] such that s = si, o = anything
                if oi != oj:                            # if oi and oj don't match, the history is invalid due to a possible failure
                    return <false, null>
        # the quorum is valid up to this point. Now we ask each replica to catch up.
        lh = max(histories)
        for i in indices:
            send('catch_up', lh - histories[i]) to replica[i]
        hashed_running_states = wait_aggregate(size(indices), on_message_received('caught_up', hashed_running_state))
        unique_running_states = unique(hashed_running_states)
        if  size(unique_running_state) > 1:
            # all hashes must be the same for a valid quorum
            return <false, null>
        return <true, unique_running_states[0]>


    on_message_received('request_reconfiguration_replica'):
        # this function is triggered when a replica triggers a reconfiguration
        # in this case, Olympus doesn't need to verify anything. It trusts the replica's request
        begin_reconfiguration()